\chapter{Evaluation} \label{chapter:evaluation}

Zur Überprüfung der Gebrauchstauglichkeit und Nützlichkeit der Web-App und des
Dashboards wurde eine summative Evaluation durchgeführt. Die Evaluation soll
ermitteln, ob Nutzergruppen Veranstaltende und Teilnehmende (vgl.
\autoref{sec:analysis-user}) ihre Schnittstelle des Systems bedienen konnten und
sich durch das System unterstützt gefühlt haben. Dieses Kapitel ist in einen
Abschnitt pro Nutzergruppe unterteilt, in welchem das Vorgehen, die Methodik und
Ergebnisse beschrieben werden.

\section{Teilnehmende}

Das System wurde insgesamt in drei Veranstaltungen eingesetzt und getestet. In
zwei der drei Veranstaltungen wurde die App durch Teilnehmende evaluiert.
Hierbei handelt es sich um die Stadt- und Campusrallye der Vorwoche an der
Universität zu Lübeck. Die Stadtrallye fand am 9.10.21, von 9 Uhr bis 16 Uhr,
auf der Lübecker Altstadt-Insel statt. Teilnehmende konnten über die gesamte
Altstadt verteilt Stationen besuchen. Insgesamt nahmen ca. 800 Studierende teil,
von denen ca. 500 die App genutzt haben. Die Campusrallye fand am 13.10.21, von
9 Uhr bis 15 Uhr statt. Dort wurden Stationen über den gesamten Campus der
Universität verteilt aufgebaut. Hierbei wurden die Studierenden in zwei Gruppen
aufgeteilt, wobei Gruppe eins von 9 Uhr bis 12 Uhr und Gruppe zwei von 12 Uhr
bis 15 Uhr vor Ort war. An der Campusrallye nahmen ebenfalls ca. 800 Studierende
Teil, von denen etwa 400 die App verwendet haben.

% Beschreiben des Einsatzszenarios
% - Stadtrallye
% - Campusrallye

% Eigenschaften
% - Teilnehmeranzahl
% - räumliche Begrenzung
% - zeitliche Begrenzung

\subsection{Vorgehen und Methodik}

Um die Gebrauchstauglichkeit und Nützlichkeit der Web-App festzustellen, wurde
ein Online-Fragebogen entworfen (s. \autoref{appendix:cd}). Dieser enthielt
Fragen zu beiden oben genannten Veranstaltungen. Zu Beginn des Fragebogens
mussten Proband:innen die Veranstaltungen anzukreuzen, an denen sie teilgenommen
haben. Von hier an enthielt der Fragebogen nur noch Fragen zu den gewählten
Veranstaltungen. In beiden Fällen wurde zuerst die Nützlichkeit der eingesetzten
Funktionalitäten bewertet. Dies geschah mit einer 4-Punkt Likert-Skala, welche
mit \textit{nicht hilfreich, wenig hilfreich, hilfreich} und \textit{sehr
    hilfreich} beschriftet wurde. Zu jeder Funktionalität wurde, je nach gewähltem
Punkt auf der Likert-Skala, in Freitext-Form nachgefragt, wieso die bewertete
Funktionalität weniger / nicht hilfreich oder (sehr) hilfreich war. Zudem wurden
einige Fragen zum Einsatz der Abzeichen und Push-Benachrichtigungen gestellt,
welche in Stadt- und Campusrallye unterschiedlich stark eingesetzt wurden.
Schließlich wurden Proband:innen befragt, wie sie das System in seiner
Gesamtheit bewerten würden und ob sie sich dieses System für andere
Veranstaltungen vorstellen könnten.

% Quantitative Befragung mit LimeSurvey
% - Fragebogen ist im Anhang
% - Gemeinsamer Fragebogen für Stadt- und Campusrallye
% - Aufteilung durch Abfrage zu Beginn
% - Likert-Skala „hilfreich“ zu Funktionalitäten, die jeweils im Einsatz waren
% - Freitext Fragen, je nach „hilfreich“-Antwort (warum? / warum nicht?)
% - Frage zu technischen Problemen

\subsection{Ergebnisse}

An dem Online-Fragebogen nahmen insgesamt 74 Proband:innen teil, wovon 63 die
Stadtrallye besuchten und 58 die Campusrallye. 53 Proband:innen (71.6\%) füllten
den Fragebogen vollständig aus. Die empfundene Nützlichkeit der Funktionalitäten
ist in \autoref{table:evaluation-result-func} dargestellt. Hierbei wurden die
Auswahlmöglichkeiten \textit{nicht hilfreich, wenig hilfreich, hilfreich} und
\textit{sehr hilfreich} als 0 bis 4 gewertet. Die schlechtestmögliche Wertung
ist somit 0 und die bestmögliche Wertung 4. In der Tabelle werden Mittelwert (M)
und Standardabweichung (SD) präsentiert.

\newcolumntype{Y}{>{\centering\arraybackslash}X}

\begin{table}[htpb]
    \def\arraystretch{1.5}
    \renewcommand\baselinestretch{1}
    \centering
    \caption{Funktionalitäten der EMI-Award-App}
    \label{table:evaluation-result-func}
    \begin{tabularx}{\textwidth}{p{2.5cm}YYYY}
        \uzlhline
        \uzlemph{Veranstaltung}                                                 & \uzlemph{\textbf{Interaktive
        Karte} \linebreak\linebreak M \linebreak (SD)}                          &
        \uzlemph{\textbf{Stationsliste} \linebreak\linebreak M \linebreak (SD)} & \uzlemph{\textbf{Virtuelles Besuchen} \linebreak M \linebreak (SD)} &
        \uzlemph{\textbf{Hilfe im FAQ-Stil} \linebreak\linebreak M \linebreak (SD)}                                                                                     \\
        \uzlhline%
        \vspace{-7pt}\parbox[b][][t]{2.5cm}{Stadtrallye (n=63)}
                                                                                & 3,85
        \linebreak (0,57)                                                       & 3,42
        \linebreak (0,72)                                                       & 2,96
        \linebreak (1,14)                                                       & 3,43
        \linebreak (1,39)                                                                                                                                               \\
        \parbox[t][][t]{2.5cm}{Campusrallye (n=58)}                             & 3,76
        \linebreak (0,43)                                                       & 3,37
        \linebreak (0,73)                                                       & 3,08
        \linebreak (0,86)
                                                                                & -                                                                                     \\
        \parbox[t][][t]{2.5cm}{Insgesamt (n=74)}                                & 3,81                                                              & 3,4 & 3,02 & 3,43 \\
        \uzlhline
    \end{tabularx}
\end{table}

Die interaktive Karte misst mit 3,81 den höchsten Mittelwert. In den Freitext
Abgaben der Proband:innen werden die Übersichtlichkeit der Stationen sowie das
kenntlich Machen der besuchten Stationen als Gründe für die Nützlichkeit
angeführt. Zudem unterstütze die Karte in der Routenplanung und somit der
Orientierung während der Veranstaltung. Jedoch sei die Übersichtlichkeit bei
mehreren Stationen innerhalb eines Gebäudes eingeschränkt. Ein:e Proband:in
bevorzugte zudem die Nutzung von Google Maps.

An dritter Stelle steht die Stationsübersicht mit einem Mittelwert von 3,42 (SD
0,72). Hier wurde das schnelle Erkennen der Stationsnähe und die Vorschau der
Stationen positiv gewertet. Zudem führte ein:e Proband:in an, dass die Anordnung
der Liste von ihr, der Übersichtlichkeit halber, bevorzugt werden würde.

Das virtuelle Besuchen besitzt, trotz eines hohen Mittelwerts von 2,96 (SD 1,14)
den niedrigsten Mittelwert. Proband:innen gaben an, dass die Markierung der
besuchten Stationen die Übersichtlichkeit fördere. Zudem wurde es als
kontaktlose Alternative zur papierbasierten Besuchsnotierung gelobt. Jedoch
wurde der Prozess des virtuellen Besuchens öfter vergessen und funktionierte aus
technischer Sicht teilweise nicht.

Der FAQ steht mit einem Mittelwert von 3,43 (SD 1,39) an zweiter Stelle, jedoch
wurde es nur in der Stadtrallye genutzt. Besonders zur Erstbenutzung wurde der FAQ als hilfreiche Ergänzung gesehen, welcher eine schnelle Hilfe für häufige
Probleme und Fragen bietet.

Da Abzeichen keine Funktionalität darstellen, die Teilnehmende direkt
unterstützt, wurde die empfundene Nützlichkeit in einer separaten Frage
ermittelt. Hierzu sollten Proband:innen angeben, ob und welchen Mehrwert sie den
Abzeichen zuweisen. Vordergründig wurde angeführt, dass die Abzeichen motivieren
und das Abschließen Spaß macht, besonders als Zeitvertreib zwischen den
Stationen. Zudem stärke es in Gruppen den Teamgeist. Anderseits ist das
Abschließen der Abzeichen teils zeitintensiv.

Die Push-Benachrichtigungen wurden nur in der Campusrallye genutzt. Aufgrund von
technischen Schwierigkeiten erhielten nur wenige Proband:innen die
Benachrichtigungen. Alle Proband:innen, bei denen die Nachrichten einging,
stimmten zu, dass sie durch jene das Gefühl bekämen, nichts
Veranstaltungsrelevantes zu verpassen.

Des Weiteren wurden Proband:innen dazu befragt, welche
Funktionalitäten ihnen gefehlt hätten. Hierbei wurden die folgenden
Funktionalitäten genannt:

\begin{itemize}[label=\bullet]
    \item Routenplanung
    \item Chat-Funktion mit Veranstaltenden
    \item Stellen einer Fragen
    \item Auslastungsindikator für Stationen
    \item Countdown für Veranstaltungsende
\end{itemize}

Außerdem sollte berücksichtigt werden, dass während der Veranstaltungen einige
technische Probleme auftraten. Um sicherzustellen, dass negative Erfahrungen
aufgrund technischer Schwierigkeiten die Ergebnisse der Evaluation nicht
verzerren, wurden Proband:innen gebeten, ihnen widerfahrene Schwierigkeiten
aufzuführen. Häufig angemerkte Punkte sind hierbei:

\begin{itemize}[label=\bullet]
    \item Login nicht möglich
    \item Langsames Laden der App
    \item Funktionsunfähige Kamera
\end{itemize}

Abschließend wurden Proband:innen gefragt, ob und wo sie sich eine App dieser
Art auch für andere Veranstaltungen wünschen würden. 95,24\% der Proband:innen
beantworteten diese Frage mit Ja. Folgende Veranstaltungskontexte
wurden als weitere Möglichkeiten angegeben:

\begin{itemize}[label=\bullet]
    \item Festivals (mit Workshopangeboten)
    \item Weihnachtsmarkt
    \item Veranstaltungen mit größeren Bereichen
    \item Messen
    \item Freizeitpark
    \item Infoveranstaltungen
\end{itemize}

\section{Veranstaltende}

Während die Stadt- und Campusrallye zur Evaluation durch Teilnehmende dient,
wurde die Seite der Veranstaltenden im Rahmen der Media Moments des EMI-Awards
getestet. Die Media Moments des EMI-Awards fanden vom 2.2.22 bis zum 20.02.22
statt. Dort war es mithilfe der App möglich, verschiedene Stationen verteilt
durch die Lübecker Innenstadt zu besuchen (vgl. \autoref{chapter:introduction}).

\subsection{Vorgehen und Methodik}

Die Evaluation wurde mittels eines qualitativen Online-Interviews mit einem
Verantwortlichen des EMI-Awards durchgeführt. Hierfür wurde ein
Interviewleitfaden entwickelt (vgl. \autoref{appendix:evaluation}). Dieser soll
die Gebrauchstauglichkeit des Systems während Organisations- und
Durchführungsphase feststellen. Hierzu wurde die Bedienung der Strapi Oberfläche
und des Dashboards evaluiert.

\subsection{Ergebnisse}

Zunächst wurde die Organisationsphase erläutert, in welcher die
veranstaltungsbezogenen Inhalte in das System integriert werden. Während des
Erstellens der Stationen ist das neue Location-Picker Plugin und die Nutzung von
Markdown zur Eintragung der Texte positiv aufgefallen. Jedoch wurde dem
Location-Picker Plugin angemerkt, dass eine manuelle Eintragung von Breiten- und
Längengrad hilfreich wäre, da die Karte in nahen Zoomstufen an Detail verliert.
Zudem wurde sich eine Vorschaufunktion für die Stationen gewünscht. Dies sei
besonders wichtig, da die Veranstaltung vor Start nicht einsehbar ist.
Schließlich wurde bemängelt, dass es keinen Hinweis zur Zeichenbegrenzung der
Kurzbeschreibung gab, weshalb Texte auf Verdacht gekürzt werden mussten, bis die
Zeichenlänge eingehalten wurde. Die Einrichtung der neuen Abzeichen wurde als
„ersichtlich“ beschrieben, wobei die Abschlussbedingung einiger Abzeichen nicht
sofort ersichtlich war. Das Eintragen der Veranstaltungsdaten in der
Konfigurationsansicht des Dashboards erschien ebenfalls ersichtlich. Jedoch
wurde angemerkt, dass einige erzwungene Daten der Stationen das Speichern
erschwerten, wenn zum Zeitpunkt des Eintragens nicht alle Informationen bekannt
waren.

In der Durchführung wurde das Dashboard als „deutlicher Mehrwert“ eingestuft.
Besonders positiv aufgefallen sind die Statistiken. Die Aufteilung in
Gesamtanzahl und pro Tag wurde als sinnvoll empfunden. Der Stationsstatistik
wurde angemerkt, dass das Anklicken einer Station zu dieser führen sollte. Dies
sei besonders praktisch, um stationsbezogene Probleme schneller ausfindig machen
zu können. Auch die Abzeicheneinreichungen wurden als „sehr eingängig“
beschrieben. Bemängelt wurde hierbei die fehlende Möglichkeit alte Einreichungen
einzusehen. Zudem würde eine Benachrichtigung bei neuen Einreichungen hilfreich
sein. Zu Feedback-Anfragen und Benachrichtigungen konnten keine Aussagen
getroffen werden, da diese nicht genutzt wurden. Trotz dessen wurde angemerkt,
dass die Funktionsweise der Feedback-Anfragen sich nicht aus der Beschreibung
der Oberfläche ergibt.

\section{Fazit}

Die Evaluation beider Seiten des Systems verlief erfolgreich. Sowohl die
Ergebnisse der Teilnehmendenbefragung als auch des Veranstaltendeninterviews
zeigen, dass das System als Unterstützung wahrgenommen wurde. Auf Seite der
Teilnehmenden wurden alle Funktionalitäten, trotz der teils schweren technischen
Probleme, überwiegend als hilfreich und sehr hilfreich eingestuft. Zudem würden
über 95\% der Teilnehmenden das System auch gerne in anderen
Veranstaltungskontexten nutzen. Auch aus Sicht der Veranstaltenden war die
Nutzung des Systems überwiegend positiv eingestuft worden. Beispielsweise wurde
das Dashboard wurde durch die Statistiken als „deutlicher Mehrwert“ bezeichnet.


% - positive Bewertung
% - nutzungwunsch für andere systeme